{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "__Advanced NLP | MSc CogSys | Potsdam University__\n",
    "\n",
    "We can install PyTorch following the instructions [here](https://pytorch.org/get-started/locally/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on [this tutorial](https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e?#ea0d) and on PyTorch's [documentation](https://pytorch.org/docs/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.nn: implements layers, loss functions and activation functions\n",
    "import torch.nn as nn\n",
    "# torch.optim: implements optimization algorithms (e.g. SGD)\n",
    "import torch.optim as optim\n",
    "# used for activation functions (deprecated?, but still used in PyTorch's github examples)\n",
    "import torch.nn.functional as F \n",
    "# torchviz to visualize computation graphs (needs graphviz)\n",
    "import torchviz\n",
    "# we use numpy for some examples\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the lecture slides, using the Graphics Processing Unit may boost the performance of our program when we are training neural networks. So let us first examine the possibility of using it in our PyTorch code. \n",
    "\n",
    "To use the GPU, PyTorch needs [Cuda](https://pytorch.org/docs/stable/notes/cuda.html), which is a Nvidia's API. In general, PyTorch's installation includes it.\n",
    "\n",
    "We can use ``cuda.is_available()`` to check whether there is any available GPU. If it returns True, we can make our calculations on the GPU. If it returns False, it can either mean that our computer or server has no GPU, or that we missed installing cuda. In that case, all computation will be performed in the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if cuda is available, the GPU will not be automatically used. We have to send our data and models to it ourselves. We will see how to do that, but first it is good practice to store the device we want to use in a variable that will be passed as arguments later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook can use the cpu for running the code.\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if it is available, otherwise use CPU.\n",
    "my_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('This notebook can use the ' + str(my_device) + ' for running the code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some servers may have more than one GPU. In that case, we can manually choose which one we would like to use. ``torch.cuda.device_count()`` returns the number of available GPUs, which are numbered starting at 0. If there is more than one, we can refer to them using ``\"cuda:0\"``, ``\"cuda:1\"``, ..., ``\"cuda:n\"``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list with all GPUs\n",
    "# torch.device(\"cuda\", n) is the same as torch.device(\"cuda:n\")\n",
    "devices = [torch.device(\"cuda\", n) for n in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember__: if we want to use the GPU, all our data, parameters and models must be sent to the GPU, preferably by the time they are created. Trying to combine tensors in the CPU with tensors in the GPU in a function will throw an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are the fundamental objects in PyTorch. They are n-dimensional arrays, very similar to Numpy arrays, with special methods. \n",
    "\n",
    "You can create a simple tensor like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "tensor([[[1, 2, 3, 4],\n",
      "         [5, 6, 7, 8]],\n",
      "\n",
      "        [[8, 7, 6, 5],\n",
      "         [4, 3, 2, 1]],\n",
      "\n",
      "        [[0, 2, 4, 6],\n",
      "         [0, 3, 5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "# a scalar\n",
    "tnsr0 = torch.tensor(1)\n",
    "# a vector\n",
    "tnsr1 = torch.tensor([1,2,3,4]) \n",
    "# a matrix\n",
    "tnsr2 = torch.tensor([[1,2,3,4], [5,6,7,8]])\n",
    "# a 3-dimensional tensor\n",
    "tnsr3 = torch.tensor([ [[1,2,3,4], [5,6,7,8]], [[8,7,6,5], [4,3,2,1]], [[0,2,4,6], [0,3,5,7]] ]) \n",
    "\n",
    "print(tnsr0)\n",
    "print(tnsr1)\n",
    "print(tnsr2)\n",
    "print(tnsr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn a Numpy array into a tensor using ``torch.from_numpy()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array([[1,2,3],[4,5,6]])\n",
    "pytorch_tensor = torch.from_numpy(np_array)\n",
    "print(pytorch_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tensors are stored at the CPU. We can move it to the GPU when we create it by passing the device as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnsr4 = torch.tensor([1,2,3], device=my_device) # my_device can be \"cpu\", \"cuda\" or \"cuda:n\"\n",
    "tnsr4.device # check in which device is the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the device of an existing tensor using ``.to()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnsr2.to(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, ``.to()`` shadows a tensor's gradient (we will learn that below), so it is always advisible to create the tensor directly on the GPU using the argument ``device``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we create a tensor, we can also specify the desired [data type](https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype), e.g. ``torch.float``, ``torch.double``, ``torch.long``. If no argument is given, the data type will be inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnsr5 = torch.tensor([1,2,3], device=my_device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty tensors or tensors filled with zeros / random numbers are created by passing the desired dimensions to ``torch.empty()``, ``torch.zeros()`` and ``torch.rand()``, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 1.0842e-19, 0.0000e+00],\n",
      "        [1.0842e-19, 9.8091e-45, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.2327, 0.1584, 0.2878],\n",
      "        [0.7005, 0.5682, 0.3744],\n",
      "        [0.7150, 0.5997, 0.3087],\n",
      "        [0.7623, 0.3082, 0.6131]])\n"
     ]
    }
   ],
   "source": [
    "# empty tensor means no values assigned yet, so it is initilized with 'garbage values'\n",
    "empty = torch.empty(4, 3, device=my_device) \n",
    "zeros = torch.zeros(4, 3, device=my_device)\n",
    "rnd = torch.rand(4, 3, device=my_device)\n",
    "print(empty)\n",
    "print(zeros)\n",
    "print(rnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the shape of a tensor using ``.shape`` or ``.size()``. In our example, tnsr3 has 3 dimensions. The first has size 3 (number of 'matrices'), the second has size 2 (number of rows) and the third has size 4 (number of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnsr3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the dimensions of a tensor, we use ``.view()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([2, 4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnsr6 = tnsr2.view(-1, 2) # meaning we want 2 columns, and -1 let it infer the number of needed rows\n",
    "tnsr6.shape, tnsr2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we want to specify only one dimension and let PyTorch infer the remaining dimensions of a tensor, we can use -1 for the unspecified dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to build a new tensor that has the same shape, device and data type of another one, but is filled with zeros or ones, we can use ``zeros_like()`` and ``ones_like()``, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnsr7 = torch.ones_like(tnsr3)\n",
    "tnsr7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dir(a_tensor)`` returns a description of all methods related to a tensor. Several of them are similar to those in a Numpy array. Some useful ones are:\n",
    "- ``.item()``: returns the value of a tensor as a plain Python number\n",
    "- ``.numpy()``: converts a tensor into a Numpy array (tensor must be on CPU)\n",
    "- ``.device()``: returns tensor location (CPU or GPU)\n",
    "- ``.type()``: returns data type of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important tip__: it is really easy to get lost with the dimensions of tensors, and the dimensions of inputs and outputs of layers and functions. A good practice is including comments with the number of dimensions, their size and what they represent for each tensor and inputs/outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py) is PyTorch's package of automatic differentiation for operations involving tensors. It [\"records a graph recording all of the operations that created the data as you execute operations, giving you a directed acyclic graph whose leaves are the input tensors and roots are the output tensors\"](https://pytorch.org/docs/stable/notes/autograd.html).\n",
    "\n",
    "Whenever we create a tensor, we can decide if such values require a gradient computation using the argument ``requires_grad``. It is False by default. If set to True, all operations involving such tensor will keep track of the backward operations required to compute its gradient, using the chain rule for derivation. \n",
    "\n",
    "All parameters we want to train in a neural network (weights) should thus be tensors whose argument requires_grad is set to True. Parameters that remain fixed during training and data tensors requires no gradient computation, so we should not waste memory by trying to keep their gradients.\n",
    "\n",
    "Gradients can only be recorded with tensors whose data type is floating point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(60., grad_fn=<DotBackward>), True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1,2,3], device=my_device, requires_grad=True, dtype=torch.float) \n",
    "data = torch.tensor([10,10,10], device=my_device, requires_grad=False, dtype=torch.float)\n",
    "result = params.dot(data)\n",
    "result, result.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we created a tensor of parameters (that requires gradient computation) and a tensor of data. Whenever we use a tensor that requires gradient in a function, the resulting tensor will also require a gradient, besides having an attribute ``.grad_fn`` that explicitly tells which backward operation is needed for PyTorch to calculate the gradient at this step during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, <DotBackward at 0x123c16750>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(params.grad_fn, data.grad_fn, result.grad_fn) # None when there was no function involved on the creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of a tensor is accumulated into its ``.grad`` attribute. Until we perform backpropagation, it is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad, data.grad, result.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we finish computing our goal result (normally the loss function in a neural network), we call the method ``.backward()`` on the final tensor. This will automatically compute all gradients. Let us see that with a pseudo loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3600., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = result**2\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may look like nothing happened. But we can see the difference on the ``.grad``attributes of all initial tensors that required gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1200., 1200., 1200.]), None, None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad, data.grad, result.grad, loss.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our params tensor has now the value of the gradient for each respective entry. Although result and loss are tensors whose flag requires_grad was set to true, they were simply intermediate steps in the computation of the loss. They serve to keep track of the reverse operations needed for backpropagation, but only the original parameters (whose attributes ``.is_leaf AND .requires_grad`` are True) will have computed gradient values after using the ``.backward()`` method.\n",
    "\n",
    "``.is_leaf`` refers to the tensor being a leaf on the computation graph. Let us see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"100pt\" height=\"157pt\"\n",
       " viewBox=\"0.00 0.00 100.00 157.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 153)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-153 96,-153 96,4 -4,4\"/>\n",
       "<!-- 4894375376 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4894375376</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"92,-21 0,-21 0,0 92,0 92,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 4894844752 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4894844752</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"87.5,-78 4.5,-78 4.5,-57 87.5,-57 87.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">DotBackward</text>\n",
       "</g>\n",
       "<!-- 4894844752&#45;&gt;4894375376 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>4894844752&#45;&gt;4894375376</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M46,-56.7787C46,-49.6134 46,-39.9517 46,-31.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"49.5001,-31.1732 46,-21.1732 42.5001,-31.1732 49.5001,-31.1732\"/>\n",
       "</g>\n",
       "<!-- 4894374672 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4894374672</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"73,-149 19,-149 19,-114 73,-114 73,-149\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (3)</text>\n",
       "</g>\n",
       "<!-- 4894374672&#45;&gt;4894844752 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4894374672&#45;&gt;4894844752</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M46,-113.6724C46,-105.8405 46,-96.5893 46,-88.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"49.5001,-88.2234 46,-78.2234 42.5001,-88.2235 49.5001,-88.2234\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x123ba3890>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the computation graph of a function\n",
    "torchviz.make_dot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Blue boxes: parameters of our model, for which we need to compute gradients\n",
    "- Gray boxes: an operation that involves gradient computing tensors\n",
    "- Green box: starting point to compute gradients, if we call ``.backward()`` on this variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us built a more elaborate example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"201pt\" height=\"328pt\"\n",
       " viewBox=\"0.00 0.00 201.00 328.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 324)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-324 197,-324 197,4 -4,4\"/>\n",
       "<!-- 4894372176 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4894372176</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"144.5,-21 51.5,-21 51.5,0 144.5,0 144.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 4894371984 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4894371984</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"144,-78 52,-78 52,-57 144,-57 144,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 4894371984&#45;&gt;4894372176 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>4894371984&#45;&gt;4894372176</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98,-56.7787C98,-49.6134 98,-39.9517 98,-31.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"101.5001,-31.1732 98,-21.1732 94.5001,-31.1732 101.5001,-31.1732\"/>\n",
       "</g>\n",
       "<!-- 4895173328 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4895173328</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"193,-135 109,-135 109,-114 193,-114 193,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"151\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CosBackward</text>\n",
       "</g>\n",
       "<!-- 4895173328&#45;&gt;4894371984 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4895173328&#45;&gt;4894371984</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M141.0311,-113.7787C133.7024,-105.8969 123.565,-94.9944 114.9705,-85.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"117.2968,-83.1133 107.9242,-78.1732 112.1705,-87.8799 117.2968,-83.1133\"/>\n",
       "</g>\n",
       "<!-- 4895173520 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4895173520</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"192.5,-192 109.5,-192 109.5,-171 192.5,-171 192.5,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"151\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">DotBackward</text>\n",
       "</g>\n",
       "<!-- 4895173520&#45;&gt;4895173328 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4895173520&#45;&gt;4895173328</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M151,-170.7787C151,-163.6134 151,-153.9517 151,-145.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"154.5001,-145.1732 151,-135.1732 147.5001,-145.1732 154.5001,-145.1732\"/>\n",
       "</g>\n",
       "<!-- 4895173712 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4895173712</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"92,-249 0,-249 0,-228 92,-228 92,-249\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 4895173712&#45;&gt;4895173520 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4895173712&#45;&gt;4895173520</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M65.7497,-227.7787C81.7355,-219.1007 104.4664,-206.7611 122.4365,-197.0059\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"124.2202,-200.0202 131.3389,-192.1732 120.8805,-193.8682 124.2202,-200.0202\"/>\n",
       "</g>\n",
       "<!-- 4895173264 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>4895173264</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"91,-135 1,-135 1,-114 91,-114 91,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">Log2Backward</text>\n",
       "</g>\n",
       "<!-- 4895173712&#45;&gt;4895173264 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>4895173712&#45;&gt;4895173264</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M46,-227.9795C46,-209.242 46,-169.7701 46,-145.3565\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"49.5001,-145.3276 46,-135.3276 42.5001,-145.3277 49.5001,-145.3276\"/>\n",
       "</g>\n",
       "<!-- 4895173904 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4895173904</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"73,-320 19,-320 19,-285 73,-285 73,-320\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (3)</text>\n",
       "</g>\n",
       "<!-- 4895173904&#45;&gt;4895173712 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4895173904&#45;&gt;4895173712</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M46,-284.6724C46,-276.8405 46,-267.5893 46,-259.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"49.5001,-259.2234 46,-249.2234 42.5001,-259.2235 49.5001,-259.2234\"/>\n",
       "</g>\n",
       "<!-- 4895173776 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>4895173776</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"192,-249 110,-249 110,-228 192,-228 192,-249\"/>\n",
       "<text text-anchor=\"middle\" x=\"151\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MvBackward</text>\n",
       "</g>\n",
       "<!-- 4895173776&#45;&gt;4895173520 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4895173776&#45;&gt;4895173520</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M151,-227.7787C151,-220.6134 151,-210.9517 151,-202.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"154.5001,-202.1732 151,-192.1732 147.5001,-202.1732 154.5001,-202.1732\"/>\n",
       "</g>\n",
       "<!-- 4894372048 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>4894372048</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"178,-320 124,-320 124,-285 178,-285 178,-320\"/>\n",
       "<text text-anchor=\"middle\" x=\"151\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (3, 3)</text>\n",
       "</g>\n",
       "<!-- 4894372048&#45;&gt;4895173776 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4894372048&#45;&gt;4895173776</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M151,-284.6724C151,-276.8405 151,-267.5893 151,-259.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"154.5001,-259.2234 151,-249.2234 147.5001,-259.2235 154.5001,-259.2234\"/>\n",
       "</g>\n",
       "<!-- 4895173264&#45;&gt;4894371984 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>4895173264&#45;&gt;4894371984</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M55.7808,-113.7787C62.9713,-105.8969 72.9174,-94.9944 81.3497,-85.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.1091,-87.9198 88.2631,-78.1732 78.9377,-83.202 84.1091,-87.9198\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x123c66a50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1 = torch.tensor([[1,1,1], [2,2,2], [3,3,3]], device=my_device, requires_grad=True, dtype=torch.float)\n",
    "params2 = torch.tensor([0.5, 0.1, 0.9], device=my_device, requires_grad=True, dtype=torch.float)\n",
    "data = torch.tensor([10, 10, 10], device=my_device, requires_grad=False, dtype=torch.float)\n",
    "\n",
    "aux1 = params1.matmul(data)\n",
    "aux2 = params2**0.5\n",
    "aux3 = aux2.dot(aux1)\n",
    "aux4 = aux3.cos() + aux2.log2()\n",
    "\n",
    "loss = aux4.sum()\n",
    "\n",
    "torchviz.make_dot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the tensor data is not shown in the computation graph, because it only presents gradient computing tensors and their dependencies. Still, we know that the data tensor was needed for the gray box MvBackward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us perform backpropagation on this loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.0195, 2.0195, 2.0195],\n",
       "         [0.9032, 0.9032, 0.9032],\n",
       "         [2.7095, 2.7095, 2.7095]]), tensor([ 7.5013, 34.3085, 14.3490]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1.grad, params2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we perform gradient descent, we need to update the parameters using the newly computed gradient values. We could do it manually by calling ``params1 = params1 - params1.grad``, but it can be really cumbersome when we have many parameters at different steps in a model.\n",
    "\n",
    "PyTorch provides optimizers that can do that automatically and more efficiently. Before learning about them on the next section, there is an important reminder to finish this part.\n",
    "\n",
    "The computation of gradients is cumulative. PyTorch keeps track of operations until we explicitly give a command to disconnet the next computations from the past. For instance, in gradient descent: we output predictions, compute the loss, compute the gradients, update the parameters. An iteration is now finished and we will restart all over. We do not want PyTorch to try to backpropagate the error back to the first iteration. \n",
    "\n",
    "To avoid that, we could manually restart the gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1.grad.zero_()\n",
    "params2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, PyTorch optimizers can also do that automatically with a simple comand that we will examine in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use ``.detach()`` to detach a tensor from the computation history, e.g. to create a new tensor with the current value of another one but without its gradient history. This new tensor can be used for other purposes and further computation that is independent of how the original values were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"75pt\" height=\"29pt\"\n",
       " viewBox=\"0.00 0.00 75.00 29.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 25)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-25 71,-25 71,4 -4,4\"/>\n",
       "<!-- 4475390056 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4475390056</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"67,-21 0,-21 0,0 67,0 67,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">NoneType</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x123c667d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_loss = loss.detach()\n",
    "torchviz.make_dot(new_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's package [torch.optim](https://pytorch.org/docs/stable/optim.html?highlight=optimizers) implements several common optimization methods such as SGD, Adam, AdaGrad, RMSprop etc. It lets us easily choose the learning rate, momentum and other hyperparameters, perform updating steps in our models with the method ``.step()`` and clean gradient history with the ``.zero_grad()`` method.\n",
    "\n",
    "Let us use the Adam optimizer to perform a gradient descent step in the loss function we computed above.\n",
    "\n",
    "We first choose an optimizer and pass a list of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = torch.tensor([[1,1,1], [2,2,2], [3,3,3]], device=my_device, requires_grad=True, dtype=torch.float)\n",
    "params2 = torch.tensor([0.5, 0.1, 0.9], device=my_device, requires_grad=True, dtype=torch.float)\n",
    "\n",
    "# first instantiate an optim object with the model's parameters and the optimizer's specific hyperparameters\n",
    "optimizer = optim.Adam([params1, params2], lr=0.0001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build the loss again and call the ``.step()`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([10, 10, 10], device=my_device, requires_grad=False, dtype=torch.float)\n",
    "\n",
    "aux1 = params1.matmul(data)\n",
    "aux2 = params2**0.5\n",
    "aux3 = aux2.dot(aux1)\n",
    "aux4 = aux3.cos() + aux2.log2()\n",
    "\n",
    "loss = aux4.sum()\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9999, 0.9999, 0.9999],\n",
       "         [1.9999, 1.9999, 1.9999],\n",
       "         [2.9999, 2.9999, 2.9999]], requires_grad=True),\n",
       " tensor([0.4999, 0.0999, 0.8999], requires_grad=True))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1, params2 # check new parameters after one update in gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.0195, 2.0195, 2.0195],\n",
       "         [0.9032, 0.9032, 0.9032],\n",
       "         [2.7095, 2.7095, 2.7095]]), tensor([ 7.5013, 34.3085, 14.3490]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1.grad, params2.grad # check how the optimizer computed and stored the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must then call ``optimizer.zero_grad()`` to make sure that the gradient computation starts again in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]), tensor([0., 0., 0.]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1.grad, params2.grad # check how the optimizer zeroed the previous gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used a psedo loss function so far. However, neural network models normally use more elaborate loss functions like mean squared error, cross entropy, hinge etc. \n",
    "\n",
    "The most usual loss functions are already implemented in PyTorch's [``.nn`` package](https://pytorch.org/docs/stable/nn.html) with their corresponding gradient computation: L1Loss, MSELoss, CrossEntropyLoss, CTCLoss, NLLLoss, PoissonNLLLoss, KLDivLoss, BCELoss, BCEWithLogitsLoss, MarginRankingLoss,  HingeEmbeddingLoss, MultiLabelMarginLoss, SmoothL1Loss, SoftMarginLoss, MultiLabelSoftMarginLoss, CosineEmbeddingLoss, MultiMarginLoss and TripletMarginLoss.\n",
    "\n",
    "Here is an example using the cross entropy with a single, non-normalized output scores and a golden class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we first instantiate a loss object, eventually passing the arguments with its hyperparameters\n",
    "crss_entrp = nn.CrossEntropyLoss()\n",
    "scores = torch.tensor([[-5, 21, 30]], dtype=torch.float)\n",
    "gold = torch.tensor([2])\n",
    "\n",
    "loss = crss_entrp(scores, gold)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build a simple model Ax=y, where x is our data and A are parameters, and suppose that we know the correct output Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(3,3, device=my_device, requires_grad=True) # random initialization of our parameters\n",
    "x = torch.tensor([0.1, 0.2, 0.3], device=my_device, requires_grad=True)\n",
    "\n",
    "y = A.matmul(x)\n",
    "Y = torch.tensor([0.2, 0.3, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first instantiate a loss function from a class in ``torch.nn``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate the loss by passing the output of our model and the true answers to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mse(y, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can continue the optimization as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()    \n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's ``torch.nn`` module provides implementations of many [activation functions](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity): ELU, Hardshrink, Hardtanh, LeakyReLU, LogSigmoid, MultiheadAttention, PReLU, ReLU, ReLU6, RReLU, SELU, CELU, Sigmoid, Softplus, Softshrink, Softsign, Tanh, Tanhshrink, Threshold, Softmin, Softmax, Softmax2d, LogSoftMax, AdaptiveLogSoftmaxWithLoss.\n",
    "\n",
    "Let us see how to create a Softmax and a ReLU layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0179, 0.0066, 0.9756])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we must first instantiate a class, then use it with our tensor as argument\n",
    "# calling F.softmax(output, dim=-1) would also work as a function, instead of a class\n",
    "\n",
    "softmax_layer = nn.Softmax(dim=-1)\n",
    "example_output = torch.tensor([-1,-2,3], dtype=torch.float)\n",
    "softmax_layer(example_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 3.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling F.relu(example_output) would also work as a function, instead of a class\n",
    "\n",
    "relu_layer = nn.ReLU()\n",
    "relu_layer(example_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have covered some important building blocks for training neural networks, but we still need to explore the models themselves. Like the loss functions, the main types of layers that compose a neural network (for instance, linear, convolutional, pooling, recurrent, dropout and transformer layer) are also implemented in the [``.nn`` package](https://pytorch.org/docs/stable/nn.html) as classes.\n",
    "\n",
    "All neural network models derive from a base class called Module. Whenever we create a new model, we should inherit the base class and write its ``__init__(self)`` method (where we define all layers) and ``forward(self, input)`` method (where we define the forward pass that returns an output).\n",
    "\n",
    "The ``.forward()`` method should not be explicitly called though. PyTorch is built to work like that, calling the model instance itself with the arguments demanded by the ``.forward()`` method will take care of everything that must happen in the background.\n",
    "\n",
    "Let us see some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e?#ea0d\n",
    "\n",
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # To make \"a\" and \"b\" real parameters of the model, we need to wrap them with nn.Parameter\n",
    "        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        return self.a + self.b * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a simple linear regression, the class ManualLinearRegression defines two parameters, initializing them randomly. The forward method returns the result of ax+b. \n",
    "\n",
    "The class ``nn.Parameter()`` is a subclass of ``Tensor``, which is automatically included into the model's parameters when we instantiate a subclass of ``nn.Module``.\n",
    "\n",
    "When we use PyTorch's implementation, we do not need to define the parameters explicitly when we choose a built-in layer. The ``LayerLinearRegression`` below is another way to do the same thing as ``ManualLinearRegression()`` using PyTorch resources: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e?#ea0d\n",
    "\n",
    "class LayerLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Instead of our custom parameters, we use a Linear layer with single input and single output\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Now it only takes a call to the layer to make predictions\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another more elaborate example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/pytorch/examples/blob/master/mnist/main.py, modified\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)   # probability of an element to be zero-ed = 0.25\n",
    "        self.dropout2 = nn.Dropout2d(0.5)    # probability of an element to be zero-ed = 0.5\n",
    "        self.fc1 = nn.Linear(9216, 128)      # input with 9216 dims, output with 128 dims\n",
    "        self.fc2 = nn.Linear(128, 10)        # input with 128 dims, output with 10 dims\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "    \n",
    "        return output\n",
    "    \n",
    "# The use of torch.nn.functional is deprecated according to https://discuss.pytorch.org/t/torch-tanh-vs-torch-nn-functional-tanh/15897.\n",
    "# We keep it here because we can still find it on existing codes, however all activation functions are available\n",
    "# on the module torch.nn as classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classifying MNIST digits, they create a more elaborate class called Net, which inherits from the base class Module. This model uses some of the many implemented layers in ``torch.nn``.\n",
    "\n",
    "The model is initialized with two convolutional layers, two dropout layers and two linear layers. Its forward method defines the forward pass: the input goes through convolution, ReLu, convolution, pooling, dropout, linearization, ReLu, droupout, linearizarion and softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the ManualLinearRegression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.6335], requires_grad=True) Parameter containing:\n",
      "tensor([-1.5776], requires_grad=True) tensor([-6.9439], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# example input and correct output\n",
    "x = torch.tensor([4], device=my_device)\n",
    "y_gold = 5\n",
    "\n",
    "model = ManualLinearRegression().to(my_device) # the model must be in the same device as the data\n",
    "\n",
    "output = model(x)\n",
    "\n",
    "# Check the values:\n",
    "print(model.a, model.b, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-23.8877]), tensor([-95.5509]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (output - y_gold)**2\n",
    "error.backward()\n",
    "model.a.grad, model.b.grad # gradients have been computed for our parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the LayerLinearRegression does the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1661]], requires_grad=True), Parameter containing:\n",
       " tensor([0.0586], requires_grad=True), tensor([-0.6058], grad_fn=<AddBackward0>)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([4], device=my_device, dtype=torch.float)\n",
    "y_gold = 5\n",
    "model2 = LayerLinearRegression().to(my_device) # the model must be in the same device as the data\n",
    "\n",
    "output2 = model2(x)\n",
    "[*model2.parameters(), output2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the values of the parameters in our model, we can use the generator ``.parameters()`` as above or call ``.state_dict()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('a', tensor([-0.3842])), ('b', tensor([-2.1189]))])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[-0.1661]])),\n",
       "             ('linear.bias', tensor([0.0586]))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or as a generator again, but with the corresponding names of the many parameters in the Net() model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1.weight', Parameter containing:\n",
       "  tensor([[[[-0.2647,  0.0923, -0.0819],\n",
       "            [-0.2305,  0.0544, -0.0637],\n",
       "            [ 0.3315, -0.2681, -0.0537]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0170, -0.2774,  0.2242],\n",
       "            [-0.2423, -0.2937,  0.0447],\n",
       "            [-0.0419, -0.1036, -0.1825]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2454, -0.1458,  0.1637],\n",
       "            [-0.2025,  0.0457,  0.2149],\n",
       "            [-0.2026, -0.1624, -0.2270]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2218,  0.2137,  0.2941],\n",
       "            [-0.2228,  0.2429, -0.2544],\n",
       "            [ 0.1378,  0.0543, -0.3303]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1729, -0.2553, -0.0567],\n",
       "            [ 0.2168,  0.0969,  0.1176],\n",
       "            [ 0.2574,  0.0115,  0.1198]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1533, -0.0754,  0.3018],\n",
       "            [ 0.2532,  0.2703, -0.2191],\n",
       "            [ 0.2210, -0.2590, -0.1457]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0894, -0.0480,  0.1805],\n",
       "            [ 0.1513,  0.2558, -0.0849],\n",
       "            [-0.2888,  0.0978,  0.0811]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1680,  0.1327,  0.1370],\n",
       "            [-0.0467,  0.0661, -0.1525],\n",
       "            [-0.1927, -0.1934,  0.2419]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0110, -0.3278,  0.2000],\n",
       "            [ 0.2280,  0.0088, -0.3301],\n",
       "            [-0.3073,  0.1592, -0.2938]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0742,  0.2902, -0.0341],\n",
       "            [ 0.1179,  0.1966, -0.1007],\n",
       "            [-0.0190, -0.1290,  0.1458]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1169, -0.0742,  0.2499],\n",
       "            [ 0.3012,  0.3214, -0.1962],\n",
       "            [ 0.1618, -0.0088,  0.0781]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2911,  0.0404,  0.2576],\n",
       "            [ 0.3240, -0.1436,  0.1783],\n",
       "            [-0.1106, -0.2060,  0.1922]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1255,  0.3207, -0.1475],\n",
       "            [ 0.0846, -0.3044, -0.0042],\n",
       "            [ 0.1858,  0.1422, -0.3067]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0723,  0.0658, -0.0705],\n",
       "            [ 0.2791,  0.2451,  0.2323],\n",
       "            [ 0.2741,  0.3040, -0.0333]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3215,  0.1838, -0.1023],\n",
       "            [-0.0405,  0.1066, -0.1034],\n",
       "            [-0.0585,  0.2829,  0.0033]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1476,  0.2712, -0.0314],\n",
       "            [-0.2550, -0.2706, -0.2319],\n",
       "            [ 0.2896, -0.2971,  0.2297]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3172,  0.0396, -0.2932],\n",
       "            [-0.0329, -0.1465,  0.2407],\n",
       "            [ 0.0046,  0.1016, -0.0135]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2566, -0.1057,  0.0709],\n",
       "            [ 0.3169,  0.0378,  0.2185],\n",
       "            [-0.1740,  0.0357,  0.2260]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1220, -0.2772,  0.3301],\n",
       "            [-0.0678, -0.1898, -0.0247],\n",
       "            [-0.1842, -0.1863,  0.0242]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3241,  0.2728,  0.0520],\n",
       "            [ 0.2385, -0.1245,  0.2706],\n",
       "            [-0.2982, -0.3097,  0.2821]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2474, -0.2367,  0.3217],\n",
       "            [-0.1203, -0.2101, -0.1709],\n",
       "            [-0.1491,  0.2962,  0.3271]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0837,  0.0752,  0.0442],\n",
       "            [-0.3108, -0.0508,  0.1097],\n",
       "            [-0.1968, -0.1829, -0.2894]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3151,  0.1523,  0.1952],\n",
       "            [ 0.1936, -0.2200, -0.1364],\n",
       "            [-0.3095,  0.0848,  0.0634]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3276, -0.0822, -0.1288],\n",
       "            [-0.1769,  0.2888, -0.1605],\n",
       "            [-0.1969,  0.0083,  0.0773]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1633,  0.0160,  0.2037],\n",
       "            [ 0.1110, -0.1948,  0.2466],\n",
       "            [-0.2343, -0.1344, -0.3040]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2457,  0.0906, -0.0515],\n",
       "            [-0.1857, -0.1126,  0.1225],\n",
       "            [ 0.0811, -0.0641, -0.1056]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0121, -0.2481, -0.1472],\n",
       "            [ 0.2413,  0.0913, -0.1582],\n",
       "            [-0.2651,  0.0093,  0.3176]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1250,  0.0216,  0.0318],\n",
       "            [ 0.1225, -0.1189, -0.2177],\n",
       "            [ 0.2156, -0.2687, -0.2049]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3180, -0.0522,  0.0550],\n",
       "            [ 0.0599, -0.2590,  0.0128],\n",
       "            [-0.2318, -0.1546,  0.0385]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2106, -0.0973, -0.1922],\n",
       "            [ 0.2115, -0.0186, -0.3007],\n",
       "            [ 0.2252,  0.3129, -0.2746]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2407,  0.2417,  0.3245],\n",
       "            [-0.1231, -0.0109,  0.0614],\n",
       "            [-0.3221, -0.3143, -0.0668]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0097, -0.2677,  0.1574],\n",
       "            [ 0.3202,  0.2197,  0.0403],\n",
       "            [ 0.0454, -0.2474,  0.1876]]]], requires_grad=True)),\n",
       " ('conv1.bias', Parameter containing:\n",
       "  tensor([ 0.2505, -0.1173, -0.0866, -0.1973,  0.2235, -0.0885, -0.0319, -0.1331,\n",
       "          -0.0745, -0.0693,  0.0882, -0.0699,  0.2339,  0.2997,  0.0893, -0.0265,\n",
       "           0.0500, -0.2789,  0.0805, -0.2389,  0.3006,  0.0402, -0.1451,  0.0480,\n",
       "           0.1144,  0.1054,  0.2229, -0.1429, -0.0806, -0.1091, -0.2622,  0.1281],\n",
       "         requires_grad=True)),\n",
       " ('conv2.weight', Parameter containing:\n",
       "  tensor([[[[-3.5775e-02,  8.9171e-03, -4.9630e-02],\n",
       "            [ 9.9617e-03, -9.3887e-03,  4.9298e-03],\n",
       "            [ 4.5888e-02, -5.1208e-02, -1.9191e-02]],\n",
       "  \n",
       "           [[ 8.7040e-03,  1.7530e-02,  5.8594e-03],\n",
       "            [ 3.3878e-03, -3.4758e-02,  4.8932e-02],\n",
       "            [ 1.8217e-02,  9.0856e-05, -1.7115e-02]],\n",
       "  \n",
       "           [[-3.8021e-02, -1.5774e-02, -3.7535e-02],\n",
       "            [ 5.2088e-02,  1.9123e-02,  2.0739e-02],\n",
       "            [-1.8338e-02, -5.3796e-02, -1.4847e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.5573e-02, -1.0142e-02,  3.3761e-02],\n",
       "            [-3.2570e-02,  5.8819e-02,  3.8510e-02],\n",
       "            [ 2.1669e-02, -4.3047e-03, -5.4547e-02]],\n",
       "  \n",
       "           [[ 2.3413e-02, -5.8609e-03, -4.8057e-02],\n",
       "            [ 2.2259e-02, -4.6802e-02, -4.3200e-03],\n",
       "            [-5.0694e-02, -1.4722e-02,  2.9497e-02]],\n",
       "  \n",
       "           [[ 4.5272e-02,  2.7011e-02,  2.2467e-02],\n",
       "            [-4.9915e-02,  4.5901e-02, -3.7775e-02],\n",
       "            [ 1.6854e-02, -1.3235e-02, -3.0036e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-9.0878e-03,  1.2489e-02, -4.0058e-02],\n",
       "            [ 7.0023e-03,  8.8969e-03, -7.7954e-03],\n",
       "            [ 2.2071e-02, -5.2751e-02,  1.6090e-02]],\n",
       "  \n",
       "           [[ 5.4110e-02,  5.4950e-04, -3.1725e-02],\n",
       "            [ 2.6716e-02, -4.4308e-02,  5.4050e-02],\n",
       "            [ 3.3164e-02, -3.4296e-02,  9.1989e-03]],\n",
       "  \n",
       "           [[ 1.1912e-02,  3.4580e-02,  6.2414e-05],\n",
       "            [ 2.4410e-02, -3.2858e-02, -1.3968e-03],\n",
       "            [-6.3442e-03, -5.2370e-02, -1.6721e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-7.9451e-03,  3.1776e-02,  5.4848e-02],\n",
       "            [-5.5507e-02, -8.0919e-03, -4.5010e-02],\n",
       "            [ 2.4552e-02, -4.2053e-02, -5.0563e-02]],\n",
       "  \n",
       "           [[-4.3687e-02,  5.7458e-02, -4.2009e-02],\n",
       "            [-4.1744e-02,  5.3223e-02, -2.8596e-02],\n",
       "            [ 4.3231e-03,  2.6799e-02, -2.0841e-02]],\n",
       "  \n",
       "           [[-1.9284e-02, -3.3505e-02,  5.4090e-02],\n",
       "            [ 2.1171e-02,  3.3683e-02, -5.8046e-02],\n",
       "            [ 3.8219e-02, -1.4838e-02,  3.2039e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 1.4411e-02,  1.7349e-02, -5.2074e-02],\n",
       "            [ 1.6996e-02,  2.4113e-02,  5.3550e-02],\n",
       "            [-4.5518e-03,  3.9294e-02,  4.8088e-02]],\n",
       "  \n",
       "           [[ 5.0978e-02, -2.8080e-02, -7.1239e-03],\n",
       "            [ 3.5018e-02,  5.1712e-02, -5.5813e-02],\n",
       "            [ 5.6443e-02, -6.8906e-03,  4.4069e-02]],\n",
       "  \n",
       "           [[ 2.0156e-02, -2.2337e-02,  1.5869e-03],\n",
       "            [-3.8261e-02,  1.6675e-02, -5.4154e-02],\n",
       "            [ 7.0759e-03, -5.6102e-02, -5.2989e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 2.5838e-02, -1.0200e-02,  3.9570e-03],\n",
       "            [ 1.0635e-02, -1.9640e-02,  3.8178e-03],\n",
       "            [-1.8253e-02, -4.8987e-02,  2.7986e-02]],\n",
       "  \n",
       "           [[-1.6094e-02, -3.9082e-02,  3.5954e-02],\n",
       "            [ 1.9733e-02, -2.0293e-02,  4.9016e-02],\n",
       "            [ 5.4275e-02, -3.7958e-02,  3.4335e-02]],\n",
       "  \n",
       "           [[-1.6978e-02,  3.7112e-02, -4.5153e-03],\n",
       "            [-5.3750e-02, -4.3790e-02, -1.9594e-02],\n",
       "            [ 5.0452e-02, -3.2746e-02, -8.2286e-03]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 2.9284e-02,  3.5363e-02, -1.2458e-02],\n",
       "            [-2.5431e-02,  4.3561e-02,  5.8115e-02],\n",
       "            [-1.3901e-03,  4.4170e-02, -3.8835e-02]],\n",
       "  \n",
       "           [[ 4.4534e-02, -4.4045e-02, -2.7429e-02],\n",
       "            [ 3.0690e-02,  5.1585e-02,  3.7226e-02],\n",
       "            [ 1.8483e-02, -1.0602e-02,  2.4506e-02]],\n",
       "  \n",
       "           [[-3.4486e-03, -4.9238e-02,  2.5382e-02],\n",
       "            [-1.2710e-02, -4.1492e-02, -9.0709e-03],\n",
       "            [-9.5487e-03, -2.2772e-02,  2.5647e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-3.8105e-02,  1.9742e-02,  4.0771e-02],\n",
       "            [ 6.6285e-03, -4.0343e-02,  4.7317e-03],\n",
       "            [-2.5035e-02,  3.3557e-02, -3.2284e-02]],\n",
       "  \n",
       "           [[-2.1349e-02,  2.7912e-02,  4.0773e-02],\n",
       "            [-4.0297e-02, -2.6669e-02,  2.8400e-02],\n",
       "            [ 4.4451e-02, -3.5686e-02, -2.1705e-02]],\n",
       "  \n",
       "           [[-2.5169e-02, -3.9599e-02,  7.5290e-04],\n",
       "            [-2.3216e-02, -2.1592e-02,  1.9542e-02],\n",
       "            [ 4.1024e-02, -9.3904e-03, -5.1379e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-6.8665e-03,  3.8694e-02, -4.9366e-02],\n",
       "            [-2.3904e-03,  3.4396e-02, -1.7402e-02],\n",
       "            [ 5.5926e-02, -3.1994e-02,  1.1001e-03]],\n",
       "  \n",
       "           [[-4.4691e-02,  4.2016e-02,  2.2749e-02],\n",
       "            [ 5.0718e-02, -4.5618e-02, -9.2972e-03],\n",
       "            [ 1.7950e-02, -2.2966e-02,  5.4651e-02]],\n",
       "  \n",
       "           [[-4.5092e-02, -1.9561e-02,  3.1858e-02],\n",
       "            [-2.2242e-02,  8.1032e-03,  4.1114e-02],\n",
       "            [-1.6021e-02, -2.8372e-02, -4.2743e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 9.4816e-05,  2.5006e-02, -1.6642e-02],\n",
       "            [-4.1837e-03, -8.8051e-03,  1.2492e-02],\n",
       "            [-2.4693e-02, -4.1409e-02,  1.5474e-02]],\n",
       "  \n",
       "           [[-4.7395e-02,  4.4526e-02,  2.0291e-02],\n",
       "            [-3.3805e-02,  2.0972e-02, -9.2859e-03],\n",
       "            [-9.0442e-03, -5.3555e-02,  2.5492e-02]],\n",
       "  \n",
       "           [[ 4.2160e-02, -4.5795e-03,  3.0953e-02],\n",
       "            [ 4.6985e-02, -2.7757e-03,  3.5874e-02],\n",
       "            [ 5.6558e-02,  1.2298e-02,  3.4554e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 6.4718e-03, -5.0792e-02, -5.6819e-02],\n",
       "            [ 4.8772e-02,  4.9664e-03,  4.6691e-02],\n",
       "            [ 4.9463e-02, -1.1160e-02,  4.7343e-02]],\n",
       "  \n",
       "           [[ 4.7638e-02,  1.6733e-02, -1.8719e-02],\n",
       "            [ 1.7283e-02, -4.4834e-02,  5.3702e-02],\n",
       "            [ 5.4198e-03, -2.5028e-02, -4.2311e-02]],\n",
       "  \n",
       "           [[-5.0823e-02, -1.2232e-03, -2.2011e-02],\n",
       "            [ 4.4548e-02,  4.8073e-02,  4.3298e-02],\n",
       "            [-4.4254e-02, -1.0646e-02,  4.4070e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-3.4466e-03,  5.8417e-02, -3.8985e-05],\n",
       "            [ 3.4338e-02, -1.6899e-02,  5.5389e-02],\n",
       "            [ 3.5022e-02,  2.6032e-02, -3.4925e-02]],\n",
       "  \n",
       "           [[-4.3822e-02, -9.5209e-03,  3.9150e-03],\n",
       "            [ 2.3854e-02,  1.6826e-02, -3.5541e-02],\n",
       "            [-3.3688e-02,  2.5782e-02, -4.6070e-02]],\n",
       "  \n",
       "           [[-8.3500e-03, -3.0478e-02, -3.9074e-02],\n",
       "            [ 2.6686e-02, -4.7150e-02,  1.0127e-02],\n",
       "            [-1.5813e-02,  5.3335e-02,  3.1353e-02]]]], requires_grad=True)),\n",
       " ('conv2.bias', Parameter containing:\n",
       "  tensor([ 0.0493, -0.0407, -0.0002,  0.0579, -0.0042, -0.0128,  0.0047,  0.0036,\n",
       "           0.0151,  0.0243,  0.0018,  0.0458,  0.0504, -0.0418,  0.0446, -0.0019,\n",
       "           0.0319,  0.0472, -0.0048,  0.0525,  0.0211,  0.0350,  0.0224,  0.0282,\n",
       "          -0.0581,  0.0013,  0.0357,  0.0508, -0.0480,  0.0008,  0.0498, -0.0550,\n",
       "           0.0055,  0.0080, -0.0587,  0.0139, -0.0453,  0.0176, -0.0132,  0.0383,\n",
       "           0.0477, -0.0257,  0.0532,  0.0480, -0.0289,  0.0473, -0.0253,  0.0566,\n",
       "          -0.0208,  0.0303,  0.0207, -0.0441,  0.0001,  0.0062, -0.0532, -0.0273,\n",
       "          -0.0080, -0.0314,  0.0546,  0.0114,  0.0239,  0.0120, -0.0190,  0.0438],\n",
       "         requires_grad=True)),\n",
       " ('fc1.weight', Parameter containing:\n",
       "  tensor([[-0.0064,  0.0067, -0.0010,  ..., -0.0009, -0.0080, -0.0058],\n",
       "          [-0.0079,  0.0021, -0.0087,  ...,  0.0064,  0.0072, -0.0082],\n",
       "          [ 0.0075, -0.0082,  0.0014,  ..., -0.0082, -0.0012, -0.0006],\n",
       "          ...,\n",
       "          [-0.0019,  0.0018, -0.0087,  ..., -0.0022,  0.0036, -0.0089],\n",
       "          [-0.0010, -0.0009,  0.0026,  ...,  0.0047,  0.0046,  0.0030],\n",
       "          [ 0.0076, -0.0103,  0.0094,  ..., -0.0016, -0.0051, -0.0090]],\n",
       "         requires_grad=True)),\n",
       " ('fc1.bias', Parameter containing:\n",
       "  tensor([ 0.0060,  0.0079,  0.0062,  0.0063, -0.0076,  0.0079,  0.0022,  0.0016,\n",
       "           0.0068,  0.0024, -0.0082, -0.0030,  0.0050,  0.0098, -0.0031,  0.0068,\n",
       "          -0.0030,  0.0034, -0.0008,  0.0083, -0.0018, -0.0100, -0.0055, -0.0057,\n",
       "          -0.0042, -0.0084, -0.0012, -0.0031, -0.0032,  0.0104,  0.0079,  0.0081,\n",
       "           0.0043, -0.0034, -0.0053,  0.0015,  0.0025,  0.0094,  0.0023,  0.0100,\n",
       "          -0.0099, -0.0029, -0.0043,  0.0056, -0.0010,  0.0029,  0.0041,  0.0075,\n",
       "           0.0100, -0.0086, -0.0096,  0.0010,  0.0050, -0.0030,  0.0046, -0.0051,\n",
       "           0.0027,  0.0057,  0.0038,  0.0066,  0.0083, -0.0017, -0.0006,  0.0090,\n",
       "          -0.0084,  0.0061,  0.0082,  0.0020, -0.0070,  0.0040, -0.0009,  0.0086,\n",
       "           0.0009, -0.0033,  0.0070, -0.0042, -0.0004, -0.0002, -0.0049, -0.0071,\n",
       "           0.0026, -0.0032,  0.0037, -0.0009, -0.0063, -0.0082,  0.0099,  0.0014,\n",
       "           0.0070, -0.0044, -0.0030, -0.0045, -0.0052,  0.0101,  0.0092, -0.0057,\n",
       "          -0.0098, -0.0071,  0.0027, -0.0086,  0.0015, -0.0054, -0.0004, -0.0095,\n",
       "           0.0036, -0.0097, -0.0034,  0.0062, -0.0035,  0.0053, -0.0076, -0.0067,\n",
       "           0.0015,  0.0029,  0.0003, -0.0098, -0.0025, -0.0040,  0.0062, -0.0078,\n",
       "           0.0090,  0.0039,  0.0041, -0.0079, -0.0005,  0.0030, -0.0074, -0.0049],\n",
       "         requires_grad=True)),\n",
       " ('fc2.weight', Parameter containing:\n",
       "  tensor([[-3.1116e-02,  4.1103e-02, -7.7478e-02,  ..., -3.6776e-02,\n",
       "           -6.7744e-02, -7.6310e-02],\n",
       "          [ 3.0319e-02, -8.6127e-02,  6.5531e-02,  ...,  4.2481e-02,\n",
       "           -8.6592e-02, -4.5876e-02],\n",
       "          [-3.7008e-02, -4.7582e-02, -1.5825e-03,  ..., -8.1746e-02,\n",
       "            6.9136e-02,  2.4395e-02],\n",
       "          ...,\n",
       "          [-4.3393e-02, -6.3637e-02,  5.0488e-02,  ..., -2.4855e-05,\n",
       "           -5.2432e-02, -3.1996e-02],\n",
       "          [ 6.8774e-02,  7.1241e-02,  8.1746e-02,  ...,  4.8507e-02,\n",
       "            5.2578e-02, -7.5657e-02],\n",
       "          [ 4.8380e-02, -2.5545e-02,  1.6598e-02,  ...,  6.8223e-02,\n",
       "            3.0629e-02, -7.2803e-02]], requires_grad=True)),\n",
       " ('fc2.bias', Parameter containing:\n",
       "  tensor([ 0.0686, -0.0553, -0.0440,  0.0589,  0.0284, -0.0852, -0.0026,  0.0879,\n",
       "          -0.0160,  0.0486], requires_grad=True))]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "[*net.named_parameters()] # named_parameters is a generator object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tips "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html?highlight=reproducibility): we can give a seed value to the random number generator at the beginning of our code, so that we can reproduce the randomly initiliazed values of our model (e.g. the weights of a neural network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1135480f0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(22) # choose any integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Weight initialization](https://pytorch.org/docs/stable/nn.init.html?highlight=initialization): each layer implemented in PyTorch has a default weight initialization method. Still, we can choose one of the many initialization methods implemented on ``torch.nn.init``. After we create a layer, we can use them to initialize the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.6550, 0.5360, 0.5379, 0.3995, 0.5657], requires_grad=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1 = nn.Linear(10, 5)\n",
    "torch.nn.init.uniform_(fc1.weight, a=0.0, b=1.0) # uniform random initializtion with numbers between 0 and 1\n",
    "torch.nn.init.uniform_(fc1.bias, a=0.0, b=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most layers include a bias term as default. We can change that by setting the argument ``bias`` to False when we instantiate a layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight_ih_l0', Parameter containing:\n",
      "tensor([[-0.5290, -0.2495, -0.6546, -0.0776,  0.6363],\n",
      "        [ 0.4360,  0.6022,  0.0298, -0.3359,  0.3532],\n",
      "        [-0.1143, -0.1145,  0.3009,  0.5490, -0.0084],\n",
      "        [ 0.3018, -0.0793,  0.5332, -0.3551, -0.4471],\n",
      "        [-0.3689,  0.6163,  0.2010, -0.1655, -0.5787],\n",
      "        [ 0.5897, -0.6905, -0.1556, -0.1666,  0.4685],\n",
      "        [ 0.4674,  0.3084, -0.3757, -0.7028,  0.4024],\n",
      "        [-0.6548,  0.2645, -0.1008, -0.0440, -0.2250]], requires_grad=True)) ('weight_hh_l0', Parameter containing:\n",
      "tensor([[-0.0476, -0.2043],\n",
      "        [ 0.6398,  0.1807],\n",
      "        [ 0.0913,  0.4826],\n",
      "        [-0.3905, -0.0268],\n",
      "        [ 0.3812, -0.0164],\n",
      "        [ 0.1966,  0.1935],\n",
      "        [-0.6253,  0.5495],\n",
      "        [-0.2971,  0.6700]], requires_grad=True)) ('bias_ih_l0', Parameter containing:\n",
      "tensor([-0.5650,  0.6931, -0.6353,  0.2439,  0.2467,  0.6340, -0.6831, -0.5406],\n",
      "       requires_grad=True)) ('bias_hh_l0', Parameter containing:\n",
      "tensor([-0.5388,  0.6045,  0.2875,  0.2773, -0.5441,  0.3015,  0.0468, -0.3301],\n",
      "       requires_grad=True)) \n",
      "\n",
      "('weight_ih_l0', Parameter containing:\n",
      "tensor([[ 0.4240, -0.1627,  0.4614, -0.1637, -0.0164],\n",
      "        [-0.6698, -0.2700, -0.1372,  0.3423,  0.0679],\n",
      "        [-0.3866, -0.6732,  0.4150, -0.1906,  0.2549],\n",
      "        [-0.0722, -0.2056, -0.4007,  0.0600,  0.2632],\n",
      "        [-0.5510,  0.5440,  0.4485,  0.3736,  0.2789],\n",
      "        [-0.0762, -0.5365,  0.2731,  0.3145,  0.0874],\n",
      "        [ 0.3150,  0.5644,  0.3615, -0.4860, -0.4203],\n",
      "        [ 0.6106,  0.6899, -0.2089, -0.2945, -0.5217]], requires_grad=True)) ('weight_hh_l0', Parameter containing:\n",
      "tensor([[ 0.2122, -0.0324],\n",
      "        [ 0.5686, -0.6509],\n",
      "        [-0.3390, -0.5097],\n",
      "        [ 0.0202, -0.4958],\n",
      "        [-0.6401, -0.6085],\n",
      "        [-0.3808,  0.2999],\n",
      "        [ 0.6734, -0.6210],\n",
      "        [-0.2429,  0.6545]], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "lstm1 = nn.LSTM(5, 2)\n",
    "lstm2 = nn.LSTM(5, 2, bias=False)\n",
    "\n",
    "print(*lstm1.named_parameters(), '\\n')\n",
    "print(*lstm2.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are not training our model, we can envelope a code snippet under ``with torch.no_grad():``. Whithin this command, PyTorch will not track the gradient, which can be more efficient (less memory consumption) when we know we will not need to compute it (e.g. during test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During evaluation, we can call ``model.eval()`` to enable the evaluation mode, which results in a different behavior that some layers should have when we are not training a model. For example, droupout normally happens only during training, but not during testing. This command thus avoids having to check all layers manually or building a separate model. During training, we must call ``model.train()`` to set it back to training mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use gradient clipping, we can call ``torch.nn.utils.clip_grad_norm_(parameters, max_norm)`` after backpropagation but before updating the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods and functions that end with an _ perform in-place modifications. Both options are normally available for the usual operations on tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5])\n",
      "tensor([2, 3])\n",
      "tensor([5, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2])\n",
    "b = torch.tensor([2,3])\n",
    "\n",
    "a.add_(3) # in-place modification, a changes\n",
    "b.add(3) # b does not change, could be printed or stored in another variable\n",
    "c = b.add(3)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``torch.save()`` can be used to save a model to the disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further important commands, also check PyTorch's [cheat sheet](https://pytorch.org/tutorials/beginner/ptcheat.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "alt-ctrl-e"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
